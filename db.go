package GojiDB

import (
	"bufio"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sort"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"time"
	"unicode/utf8"
)

type GojiDB struct {
	config          *GojiDBConfig
	keyDir          *ConcurrentMap
	activeFile      *os.File
	readFiles       map[uint32]*os.File
	activeFileID    uint32
	mu              sync.RWMutex
	metrics         *Metrics
	ttlTicker       *time.Ticker
	stopChan        chan struct{}
	ttlManager      *TTLManager
	wg              sync.WaitGroup
	blockCache      *BlockCache
	keyCache        *KeyCache
	smartCompressor *SmartCompressor
	walManager      *WALManager
	closed          bool
}

func NewGojiDB(config *GojiDBConfig) (*GojiDB, error) {
	if err := os.MkdirAll(config.DataPath, 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: %v", err)
	}
	if err := os.MkdirAll(filepath.Join(config.DataPath, SnapshotDir), 0755); err != nil {
		return nil, fmt.Errorf("åˆ›å»ºå¿«ç…§ç›®å½•å¤±è´¥: %v", err)
	}

	// æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨ç¼“å­˜
	var blockCache *BlockCache
	var keyCache *KeyCache

	if config.CacheConfig.EnableCache {
		blockCache = NewBlockCache(config.CacheConfig.BlockCacheSize, 4096)
		keyCache = NewKeyCache(config.CacheConfig.KeyCacheSize)
	} else {
		blockCache = NewBlockCache(0, 4096) // ç¦ç”¨ç¼“å­˜
		keyCache = NewKeyCache(0)           // ç¦ç”¨ç¼“å­˜
	}

	db := &GojiDB{
		config:    config,
		keyDir:    NewConcurrentMap(16),
		readFiles: make(map[uint32]*os.File),
		metrics: &Metrics{
			StartTime:  time.Now(),
			SystemInfo: getSystemDetails(),
		},
		stopChan:   make(chan struct{}),
		blockCache: blockCache,
		keyCache:   keyCache,
	}

	if err := db.rebuildKeyDir(); err != nil {
		return nil, fmt.Errorf("é‡å»ºç´¢å¼•å¤±è´¥: %v", err)
	}
	if err := db.openActiveFile(); err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ´»è·ƒæ–‡ä»¶å¤±è´¥: %v", err)
	}
	if config.EnableTTL {
		db.ttlManager = NewTTLManager(func(key string) {
			db.Delete(key)
		})
	}

	// åˆå§‹åŒ–æ™ºèƒ½å‹ç¼©å™¨
	if config.SmartCompression != nil {
		db.smartCompressor = NewSmartCompressor(config.SmartCompression)
	}
	
	// åˆå§‹åŒ–WALç®¡ç†å™¨
	if config.EnableWAL {
		wal, err := NewWALManager(config)
		if err != nil {
			return nil, fmt.Errorf("åˆå§‹åŒ–WALç®¡ç†å™¨å¤±è´¥: %v", err)
		}
		db.walManager = wal
		
		// æ‰§è¡Œå´©æºƒæ¢å¤
		if err := wal.Recover(db); err != nil {
			return nil, fmt.Errorf("WALæ¢å¤å¤±è´¥: %v", err)
		}
	}
	
	return db, nil
}

func (db *GojiDB) Close() error {
	db.mu.Lock()
	if db.closed {
		db.mu.Unlock()
		return nil
	}
	db.closed = true
	db.mu.Unlock()

	if db.ttlTicker != nil {
		db.ttlTicker.Stop()
	}
	if db.ttlManager != nil {
		db.ttlManager.Stop()
	}
	if db.smartCompressor != nil {
		db.smartCompressor.Close()
	}
	if db.walManager != nil {
		db.walManager.Close()
	}
	
	if db.stopChan != nil {
		close(db.stopChan)
	}
	db.wg.Wait()

	db.mu.Lock()
	defer db.mu.Unlock()

	if db.activeFile != nil {
		db.activeFile.Sync()
		db.activeFile.Close()
		db.activeFile = nil
	}
	for _, f := range db.readFiles {
		f.Close()
	}
	return nil
}

func (db *GojiDB) Put(key string, value []byte) error {
	return db.PutWithTTL(key, value, 0)
}

func (db *GojiDB) PutWithTTL(key string, value []byte, ttl time.Duration) error {
	if key == "" {
		return fmt.Errorf("é”®ä¸èƒ½ä¸ºç©º")
	}
	if db.config.EnableMetrics {
		atomic.AddInt64(&db.metrics.TotalWrites, 1)
	}
	compressed, algorithm, err := db.compress(value)
	if err != nil {
		return fmt.Errorf("å‹ç¼©å¤±è´¥: %v", err)
	}
	entry := &Entry{
		Timestamp:   uint32(time.Now().Unix()),
		KeySize:     uint16(len(key)),
		ValueSize:   uint32(len(compressed)),
		Compression: algorithm,
		Key:         []byte(key),
		Value:       compressed,
	}
	if ttl > 0 {
		entry.TTL = uint32(time.Now().Add(ttl).Unix())
	} else if ttl < 0 {
		// è´ŸTTLç«‹å³è¿‡æœŸï¼Œè®¾ç½®ä¸ºå½“å‰æ—¶é—´
		entry.TTL = uint32(time.Now().Unix())
	}
	entry.CRC = db.calculateCRC(entry)

	db.mu.Lock()
	defer db.mu.Unlock()

	data, err := db.serializeEntry(entry)
	if err != nil {
		return err
	}

	if db.activeFile != nil {
		if stat, err := db.activeFile.Stat(); err == nil && stat.Size()+int64(len(data)) > db.config.MaxFileSize {
			if err := db.rotateActiveFile(); err != nil {
				return fmt.Errorf("è½®è½¬æ–‡ä»¶å¤±è´¥: %v", err)
			}
		}
	}

	pos, err := db.activeFile.Seek(0, io.SeekEnd)
	if err != nil {
		return err
	}
	if _, err := db.activeFile.Write(data); err != nil {
		return err
	}
	if db.config.SyncWrites {
		db.activeFile.Sync()
	}

	// å†™å…¥WALè®°å½•
	if db.walManager != nil {
		walRecord := &WALRecord{
			Type:      WALPut,
			Timestamp: uint64(time.Now().UnixNano()),
			Key:       key,
			Value:     value,
		}
		if err := db.walManager.WriteRecord(walRecord); err != nil {
			return fmt.Errorf("å†™å…¥WALå¤±è´¥: %v", err)
		}
	}

	// ä½¿ç”¨æ–°çš„å¹¶å‘Mapå†™å…¥
	db.keyDir.Set(key, &KeyDir{
		FileID:      db.activeFileID,
		ValueSize:   entry.ValueSize,
		ValuePos:    uint64(pos + HeaderSize + int64(entry.KeySize)),
		Timestamp:   entry.Timestamp,
		TTL:         entry.TTL,
		Compression: entry.Compression,
		Deleted:     false,
	})

	// æ›´æ–°ç¼“å­˜
	db.keyCache.SetKeyDir(key, &KeyDir{
		FileID:      db.activeFileID,
		ValueSize:   entry.ValueSize,
		ValuePos:    uint64(pos + HeaderSize + int64(entry.KeySize)),
		Timestamp:   entry.Timestamp,
		Compression: entry.Compression,
		Deleted:     false,
	})

	// ä½¿ç›¸å…³å—ç¼“å­˜å¤±æ•ˆ
	db.blockCache.InvalidateFile(db.activeFileID)

	// æ¯1000æ¬¡å†™å…¥è‡ªåŠ¨è§¦å‘åå°å‹ç¼©
	if db.config.EnableMetrics && atomic.LoadInt64(&db.metrics.TotalWrites)%1000 == 0 {
		go func() {
			time.Sleep(100 * time.Millisecond)
			db.Compact()
		}()
	}
	return nil
}

// æ‰¹é‡å†™å…¥æ“ä½œ
func (db *GojiDB) BatchPut(items map[string][]byte) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	batchSize := 0
	for key, value := range items {
		if key == "" {
			continue
		}
		compressed, algorithm, err := db.compress(value)
		if err != nil {
			return fmt.Errorf("å‹ç¼©å¤±è´¥: %v", err)
		}

		entry := &Entry{
			Timestamp:   uint32(time.Now().Unix()),
			KeySize:     uint16(len(key)),
			ValueSize:   uint32(len(compressed)),
			Compression: algorithm,
			Key:         []byte(key),
			Value:       compressed,
		}
		entry.CRC = db.calculateCRC(entry)

		data, err := db.serializeEntry(entry)
		if err != nil {
			return err
		}

		if db.activeFile != nil {
			if stat, err := db.activeFile.Stat(); err == nil && stat.Size()+int64(len(data)) > db.config.MaxFileSize {
				if err := db.rotateActiveFile(); err != nil {
					return fmt.Errorf("è½®è½¬æ–‡ä»¶å¤±è´¥: %v", err)
				}
			}
		}

		pos, err := db.activeFile.Seek(0, io.SeekEnd)
		if err != nil {
			return err
		}
		if _, err := db.activeFile.Write(data); err != nil {
			return err
		}

		batchSize += len(data)
		db.keyDir.Set(key, &KeyDir{
			FileID:      db.activeFileID,
			ValueSize:   entry.ValueSize,
			ValuePos:    uint64(pos + HeaderSize + int64(entry.KeySize)),
			Timestamp:   entry.Timestamp,
			Compression: entry.Compression,
			Deleted:     false,
		})

		if db.config.EnableMetrics {
			atomic.AddInt64(&db.metrics.TotalWrites, 1)
		}
	}

	if db.config.SyncWrites {
		db.activeFile.Sync()
	}
	return nil
}

// æ‰¹é‡è¯»å–æ“ä½œ
func (db *GojiDB) BatchGet(keys []string) (map[string][]byte, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	results := make(map[string][]byte)
	for _, key := range keys {
		if key == "" {
			continue
		}

		info, ok := db.keyDir.Get(key)
		if !ok || info.Deleted {
			// ä¸å­˜åœ¨çš„é”®è¿”å›ç©ºå­—èŠ‚æ•°ç»„
			results[key] = []byte{}
			continue
		}

		now := uint32(time.Now().Unix())
		if info.TTL > 0 && now >= info.TTL {
			// è¿‡æœŸçš„é”®è¿”å›ç©ºå­—èŠ‚æ•°ç»„
			results[key] = []byte{}
			continue
		}

		var data []byte
		var err error
		if info.FileID == db.activeFileID {
			data = make([]byte, info.ValueSize)
			_, err = db.activeFile.ReadAt(data, int64(info.ValuePos))
		} else {
			filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", info.FileID))
			f, openErr := os.Open(filename)
			if openErr != nil {
				// æ–‡ä»¶æ‰“å¼€å¤±è´¥ï¼Œè¿”å›ç©ºå­—èŠ‚æ•°ç»„
				results[key] = []byte{}
				continue
			}
			defer f.Close()
			data = make([]byte, info.ValueSize)
			_, err = f.ReadAt(data, int64(info.ValuePos))
		}

		if err == nil {
			decompressed, err := db.decompress(data, info.Compression)
			if err == nil {
				results[key] = decompressed
			} else {
				// è§£å‹å¤±è´¥ï¼Œè¿”å›ç©ºå­—èŠ‚æ•°ç»„
				results[key] = []byte{}
			}
		} else {
			// è¯»å–å¤±è´¥ï¼Œè¿”å›ç©ºå­—èŠ‚æ•°ç»„
			results[key] = []byte{}
		}

		if db.config.EnableMetrics {
			atomic.AddInt64(&db.metrics.TotalReads, 1)
		}
	}

	return results, nil
}

func (db *GojiDB) Get(key string) ([]byte, error) {
	if key == "" {
		return nil, fmt.Errorf("é”®ä¸èƒ½ä¸ºç©º")
	}
	if db.config.EnableMetrics {
		atomic.AddInt64(&db.metrics.TotalReads, 1)
	}

	// å°è¯•ä»é”®ç¼“å­˜è·å–
	if cachedKeyDir, found := db.keyCache.GetKeyDir(key); found {
		info := cachedKeyDir
		now := uint32(time.Now().Unix())
		if info.TTL > 0 && now >= info.TTL {
			go db.expireKey(key)
			if db.config.EnableMetrics {
				atomic.AddInt64(&db.metrics.ExpiredKeyCount, 1)
			}
			return nil, fmt.Errorf("é”®å·²è¿‡æœŸ")
		}

		// å°è¯•ä»å—ç¼“å­˜è·å–æ•°æ®
		if cachedData, found := db.blockCache.GetBlock(info.FileID, info.ValuePos, info.ValueSize); found {
			result, dErr := db.decompress(cachedData, info.Compression)
			if dErr == nil {
				if db.config.EnableMetrics {
					atomic.AddInt64(&db.metrics.CacheHits, 1)
				}
				return result, nil
			}
		}
	}

	db.mu.RLock()
	defer db.mu.RUnlock()

	info, ok := db.keyDir.Get(key)
	if !ok || info.Deleted {
		if db.config.EnableMetrics {
			atomic.AddInt64(&db.metrics.CacheMisses, 1)
		}
		return nil, fmt.Errorf("é”®ä¸å­˜åœ¨")
	}

	// æ›´æ–°é”®ç¼“å­˜
	db.keyCache.SetKeyDir(key, info)

	now := uint32(time.Now().Unix())
	if info.TTL > 0 && now >= info.TTL {
		go db.expireKey(key)
		if db.config.EnableMetrics {
			atomic.AddInt64(&db.metrics.ExpiredKeyCount, 1)
		}
		return nil, fmt.Errorf("é”®å·²è¿‡æœŸ")
	}

	var data []byte
	var err error

	// è®¡ç®—å—å¯¹é½çš„è¯»å–ä½ç½®
	blockStart := (info.ValuePos / uint64(db.blockCache.blockSize)) * uint64(db.blockCache.blockSize)
	blockEnd := blockStart + uint64(db.blockCache.blockSize)
	if blockEnd > blockStart+uint64(info.ValueSize) {
		blockEnd = blockStart + uint64(info.ValueSize)
	}

	// å°è¯•ä»å—ç¼“å­˜è·å–
	if cachedData, found := db.blockCache.GetBlock(info.FileID, blockStart, uint32(blockEnd-blockStart)); found {
		// è®¡ç®—åœ¨å—å†…çš„åç§»
		offsetInBlock := info.ValuePos - blockStart
		if offsetInBlock+uint64(info.ValueSize) <= uint64(len(cachedData)) {
			data = cachedData[offsetInBlock : offsetInBlock+uint64(info.ValueSize)]
		} else {
			// è¾¹ç•Œè¶…å‡ºï¼Œç›´æ¥ä»æ–‡ä»¶è¯»å–
			data = make([]byte, info.ValueSize)
			if info.FileID == db.activeFileID {
				_, err = db.activeFile.ReadAt(data, int64(info.ValuePos))
			} else {
				filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", info.FileID))
				f, openErr := os.Open(filename)
				if openErr != nil {
					return nil, openErr
				}
				defer f.Close()
				_, err = f.ReadAt(data, int64(info.ValuePos))
			}
		}
	} else {
		// ä»æ–‡ä»¶è¯»å–
		if info.FileID == db.activeFileID {
			data = make([]byte, info.ValueSize)
			_, err = db.activeFile.ReadAt(data, int64(info.ValuePos))
		} else {
			filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", info.FileID))
			f, openErr := os.Open(filename)
			if openErr != nil {
				atomic.AddInt64(&db.metrics.CacheMisses, 1)
				return nil, openErr
			}
			defer f.Close()
			data = make([]byte, info.ValueSize)
			_, err = f.ReadAt(data, int64(info.ValuePos))
		}

		// æ›´æ–°å—ç¼“å­˜
		if err == nil {
			blockData := make([]byte, db.blockCache.blockSize)
			if info.FileID == db.activeFileID {
				_, _ = db.activeFile.ReadAt(blockData, int64(blockStart))
			} else {
				filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", info.FileID))
				f, _ := os.Open(filename)
				if f != nil {
					defer f.Close()
					_, _ = f.ReadAt(blockData, int64(blockStart))
				}
			}
			db.blockCache.SetBlock(info.FileID, blockStart, blockData)
		}
	}

	if err != nil {
		atomic.AddInt64(&db.metrics.CacheMisses, 1)
		return nil, err
	}

	result, dErr := db.decompress(data, info.Compression)
	if dErr != nil {
		atomic.AddInt64(&db.metrics.CacheMisses, 1)
		return nil, dErr
	}

	if db.config.EnableMetrics {
		atomic.AddInt64(&db.metrics.CacheHits, 1)
	}
	return result, nil
}

func (db *GojiDB) Delete(key string) error {
	if key == "" {
		return fmt.Errorf("é”®ä¸èƒ½ä¸ºç©º")
	}
	db.mu.Lock()
	defer db.mu.Unlock()

	// æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
	_, exists := db.keyDir.Get(key)
	if !exists {
		return fmt.Errorf("é”®ä¸å­˜åœ¨")
	}

	// ä½¿ç”¨Entryå¯¹è±¡æ± 
	e := GlobalEntryPool.GetEntry()
	defer GlobalEntryPool.PutEntry(e)

	val, _, _ := db.compress([]byte(TombstoneValue))
	e.Timestamp = uint32(time.Now().Unix())
	e.KeySize = uint16(len(key))
	e.ValueSize = uint32(len(val))
	e.Compression = db.config.CompressionType
	e.Key = []byte(key)
	e.Value = val
	e.CRC = db.calculateCRC(e)

	data, _ := db.serializeEntry(e)
	if _, err := db.activeFile.Write(data); err != nil {
		return err
	}
	if db.config.SyncWrites {
		db.activeFile.Sync()
	}

	// å½’è¿˜åºåˆ—åŒ–ç¼“å†²åŒºåˆ°å†…å­˜æ± 
	if len(data) > 0 {
		GlobalAdaptivePool.PutBuffer(&data)
	}

	// å†™å…¥WALè®°å½•
	if db.walManager != nil {
		walRecord := &WALRecord{
			Type:      WALDelete,
			Timestamp: uint64(time.Now().UnixNano()),
			Key:       key,
		}
		if err := db.walManager.WriteRecord(walRecord); err != nil {
			return fmt.Errorf("å†™å…¥WALå¤±è´¥: %v", err)
		}
	}

	// æ ‡è®°ä¸ºå·²åˆ é™¤
	info, _ := db.keyDir.Get(key)
	info.Deleted = true
	info.Timestamp = e.Timestamp

	// ä» TTL ç®¡ç†å™¨ä¸­ç§»é™¤
	if db.ttlManager != nil {
		db.ttlManager.Remove(key)
	}

	// ä»ç¼“å­˜ä¸­ç§»é™¤
	db.keyCache.RemoveKey(key)
	db.blockCache.InvalidateFile(db.activeFileID)

	// æ›´æ–°æŒ‡æ ‡
	if db.config.EnableMetrics {
		atomic.AddInt64(&db.metrics.TotalDeletes, 1)
	}

	return nil
}

func (db *GojiDB) ListKeys() []string {
	db.mu.RLock()
	defer db.mu.RUnlock()
	now := uint32(time.Now().Unix())
	keys := make([]string, 0, db.keyDir.Size())
	db.keyDir.Range(func(key string, info *KeyDir) bool {
		if !info.Deleted && (info.TTL == 0 || now <= info.TTL) {
			keys = append(keys, key)
		}
		return true
	})
	sort.Strings(keys)
	return keys
}

func (db *GojiDB) SetTTL(key string, ttl time.Duration) error {
	db.mu.Lock()
	defer db.mu.Unlock()
	info, ok := db.keyDir.Get(key)
	if !ok || info.Deleted {
		return fmt.Errorf("é”®ä¸å­˜åœ¨")
	}
	if ttl > 0 {
		info.TTL = uint32(time.Now().Add(ttl).Unix())
	} else {
		info.TTL = 0
	}
	return nil
}

func (db *GojiDB) GetTTL(key string) (time.Duration, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()
	info, ok := db.keyDir.Get(key)
	if !ok || info.Deleted {
		return 0, fmt.Errorf("é”®ä¸å­˜åœ¨")
	}
	if info.TTL == 0 {
		return -1, nil
	}
	now := uint32(time.Now().Unix())
	if now >= info.TTL {
		return 0, fmt.Errorf("é”®å·²è¿‡æœŸ")
	}
	return time.Duration(int64(info.TTL)-int64(now)) * time.Second, nil
}

// ======== å†…éƒ¨å®ç° ========

func (db *GojiDB) startTTLCleanup() {
	db.ttlTicker = time.NewTicker(db.config.TTLCheckInterval)
	db.wg.Add(1)
	go func() {
		defer db.wg.Done()
		for {
			select {
			case <-db.ttlTicker.C:
				db.cleanupExpiredKeys()
			case <-db.stopChan:
				return
			}
		}
	}()
}

func (db *GojiDB) cleanupExpiredKeys() {
	db.mu.Lock()
	defer db.mu.Unlock()
	now := uint32(time.Now().Unix())
	expired := make([]string, 0, 16)
	db.keyDir.Range(func(k string, info *KeyDir) bool {
		if !info.Deleted && info.TTL > 0 && now >= info.TTL {
			expired = append(expired, k)
		}
		return true
	})
	for _, k := range expired {
		_ = db.deleteInternal(k)
		if db.config.EnableMetrics {
			atomic.AddInt64(&db.metrics.ExpiredKeyCount, 1)
		}
	}
}

func (db *GojiDB) expireKey(key string) {
	db.mu.Lock()
	defer db.mu.Unlock()
	if info, ok := db.keyDir.Get(key); ok && !info.Deleted {
		_ = db.deleteInternal(key)
	}
}

func (db *GojiDB) rebuildKeyDir() error {
	files, err := filepath.Glob(filepath.Join(db.config.DataPath, "*.data"))
	if err != nil {
		return err
	}
	if len(files) == 0 {
		db.activeFileID = 1
		return nil
	}
	maxID := uint32(0)
	for _, f := range files {
		id, err := db.parseFileID(f)
		if err == nil && id > maxID {
			maxID = id
		}
	}
	db.activeFileID = maxID

	// æŒ‰æ–‡ä»¶IDæ•°å­—æ’åºï¼Œè€Œä¸æ˜¯å­—ç¬¦ä¸²æ’åº
	sort.Slice(files, func(i, j int) bool {
		id1, err1 := db.parseFileID(files[i])
		id2, err2 := db.parseFileID(files[j])
		if err1 != nil || err2 != nil {
			return files[i] < files[j]
		}
		return id1 < id2
	})

	for _, f := range files {
		if err := db.processFile(f); err != nil {
			fmt.Printf("è·³è¿‡æŸåæ–‡ä»¶ %s: %v\n", f, err)
		}
	}
	return nil
}

func (db *GojiDB) processFile(filename string) error {
	id, err := db.parseFileID(filename)
	if err != nil {
		return err
	}
	f, err := os.Open(filename)
	if err != nil {
		return err
	}
	defer f.Close()

	stat, _ := f.Stat()
	fmt.Printf("å¤„ç†æ–‡ä»¶ %s: ID=%d, å¤§å°=%d\n", filename, id, stat.Size())

	r := bufio.NewReader(f)
	offset := int64(0)
	entryCount := 0

	for {
		e, sz, err := db.readEntry(r)
		if err == io.EOF {
			fmt.Printf("æ–‡ä»¶ %s å¤„ç†å®Œæˆ: æ‰¾åˆ° %d ä¸ªæœ‰æ•ˆæ¡ç›®\n", filename, entryCount)
			break
		}
		if err != nil {
			fmt.Printf("è¯»å–æ¡ç›®é”™è¯¯: %v, è·³è¿‡ %d å­—èŠ‚\n", err, sz)
			offset += int64(sz)
			continue
		}

		if !db.verifyCRC(e) {
			fmt.Printf("CRCéªŒè¯å¤±è´¥, è·³è¿‡æ¡ç›®\n")
			offset += int64(sz)
			continue
		}

		key := string(e.Key)
		valuePos := offset + HeaderSize + int64(e.KeySize)
		val, _ := db.decompress(e.Value, e.Compression)
		isTomb := string(val) == TombstoneValue

		// è°ƒè¯•è¾“å‡ºå·²ç§»é™¤: key=%s, valueSize=%d, timestamp=%d, tombstone=%v
		// åŸè°ƒè¯•ä»£ç : fmt.Printf(...)

		if old, ok := db.keyDir.Get(key); !ok || e.Timestamp >= old.Timestamp {
			db.keyDir.Set(key, &KeyDir{
				FileID:      id,
				ValueSize:   e.ValueSize,
				ValuePos:    uint64(valuePos),
				Timestamp:   e.Timestamp,
				TTL:         e.TTL,
				Compression: e.Compression,
				Deleted:     isTomb,
			})
			// è°ƒè¯•è¾“å‡ºå·²ç§»é™¤: æ›´æ–°keyDir: key=%s, fileID=%d
			// åŸè°ƒè¯•ä»£ç : fmt.Printf(...)
			entryCount++
		}
		offset += int64(sz)
	}
	return nil
}

func (db *GojiDB) parseFileID(filename string) (uint32, error) {
	base := filepath.Base(filename)
	name := strings.TrimSuffix(base, ".data")
	id, err := strconv.ParseUint(name, 10, 32)
	return uint32(id), err
}

func (db *GojiDB) openActiveFile() error {
	filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", db.activeFileID))
	if db.activeFile != nil {
		db.activeFile.Close()
		db.activeFile = nil
	}
	f, err := os.OpenFile(filename, os.O_CREATE|os.O_RDWR|os.O_APPEND, DefaultFilePerm)
	if err != nil {
		return err
	}
	db.activeFile = f
	return nil
}

func (db *GojiDB) rotateActiveFile() error {
	if db.activeFile != nil {
		db.activeFile.Sync()
		db.activeFile.Close()
		readFile, err := os.Open(filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", db.activeFileID)))
		if err == nil {
			db.readFiles[db.activeFileID] = readFile
		}
	}
	db.activeFileID++
	return db.openActiveFile()
}

func (db *GojiDB) verifyCRC(e *Entry) bool {
	return db.calculateCRC(e) == e.CRC
}

func (db *GojiDB) deleteInternal(key string) error {
	info, ok := db.keyDir.Get(key)
	if !ok || info.Deleted {
		return fmt.Errorf("é”®ä¸å­˜åœ¨")
	}
	val, _, _ := db.compress([]byte(TombstoneValue))
	e := &Entry{
		Timestamp:   uint32(time.Now().Unix()),
		KeySize:     uint16(len(key)),
		ValueSize:   uint32(len(val)),
		Compression: db.config.CompressionType,
		Key:         []byte(key),
		Value:       val,
	}
	e.CRC = db.calculateCRC(e)
	data, _ := db.serializeEntry(e)
	if _, err := db.activeFile.Write(data); err != nil {
		return err
	}
	if db.config.SyncWrites {
		db.activeFile.Sync()
	}
	info.Deleted = true
	info.Timestamp = e.Timestamp
	return nil
}

// Compact æ‰§è¡Œæ•°æ®åˆå¹¶ï¼ˆä¸å•æ–‡ä»¶ç‰ˆå®Œå…¨ä¸€è‡´ï¼‰
func (db *GojiDB) Compact() error {
	if db.config.EnableMetrics {
		atomic.AddInt64(&db.metrics.CompactionCount, 1)
	}

	db.mu.Lock()
	defer db.mu.Unlock()

	// 1. åˆ›å»ºä¸´æ—¶åˆå¹¶æ–‡ä»¶
	compactFileName := filepath.Join(db.config.DataPath, fmt.Sprintf("compact_%d.data", time.Now().UnixNano()))
	compactFile, err := os.Create(compactFileName)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºåˆå¹¶æ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer compactFile.Close()

	// 2. æ”¶é›†æ´»è·ƒé”®
	activeKeys := make(map[string]*KeyDir)
	now := uint32(time.Now().Unix())
	db.keyDir.Range(func(key string, kd *KeyDir) bool {
		if !kd.Deleted && (kd.TTL == 0 || now <= kd.TTL) {
			activeKeys[key] = kd
		}
		return true
	})

	// 3. é‡å†™æ´»è·ƒé”®åˆ°æ–°æ–‡ä»¶
	// 5. æ›´æ–°å†…å­˜ç´¢å¼•
	newKeyDir := make(map[string]*KeyDir)
	offset := int64(0)

	for key, oldKD := range activeKeys {
		// è¯»å–åŸå§‹æ•°æ®
		var data []byte
		var err error
		if oldKD.FileID == db.activeFileID {
			data = make([]byte, oldKD.ValueSize)
			_, err = db.activeFile.ReadAt(data, int64(oldKD.ValuePos))
		} else {
			filename := filepath.Join(db.config.DataPath, fmt.Sprintf("%d.data", oldKD.FileID))
			f, openErr := os.Open(filename)
			if openErr != nil {
				// æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤é”®
				continue
			}
			data = make([]byte, oldKD.ValueSize)
			_, err = f.ReadAt(data, int64(oldKD.ValuePos))
			f.Close()
		}

		// å¦‚æœè¯»å–å¤±è´¥ï¼Œè·³è¿‡æ­¤é”®
		if err != nil {
			continue
		}

		// è§£å‹ç¼©å¹¶é‡æ–°å‹ç¼©
		val, decompErr := db.decompress(data, oldKD.Compression)
		if decompErr != nil {
			// è§£å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
			val = data
		}

		newCompressed, _, compErr := db.compress(val)
		if compErr != nil {
			// å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
			newCompressed = val
		}

		// æ„å»ºæ–°æ¡ç›®
		entry := &Entry{
			Timestamp:   oldKD.Timestamp,
			TTL:         oldKD.TTL,
			KeySize:     uint16(len(key)),
			ValueSize:   uint32(len(newCompressed)),
			Compression: db.config.CompressionType,
			Key:         []byte(key),
			Value:       newCompressed,
		}
		entry.CRC = db.calculateCRC(entry)

		// å†™å…¥åˆå¹¶æ–‡ä»¶
		serialized, _ := db.serializeEntry(entry)
		if _, err := compactFile.Write(serialized); err != nil {
			continue
		}

		newKeyDir[key] = &KeyDir{
			FileID:      1, // æ–°æ–‡ä»¶IDå›ºå®šä¸º1
			ValueSize:   entry.ValueSize,
			ValuePos:    uint64(offset + HeaderSize + int64(entry.KeySize)),
			Timestamp:   entry.Timestamp,
			TTL:         entry.TTL,
			Compression: entry.Compression,
			Deleted:     false,
		}
		offset += int64(len(serialized))
	}

	// 4. åŒæ­¥&å…³é—­åˆå¹¶æ–‡ä»¶
	_ = compactFile.Sync()
	_ = compactFile.Close()

	// 5. å…³é—­æ—§æ–‡ä»¶
	if db.activeFile != nil {
		_ = db.activeFile.Close()
		db.activeFile = nil
	}
	for _, f := range db.readFiles {
		_ = f.Close()
	}
	db.readFiles = make(map[uint32]*os.File)

	// 6. åˆ é™¤æ—§æ•°æ®æ–‡ä»¶
	oldFiles, _ := filepath.Glob(filepath.Join(db.config.DataPath, "*.data"))
	for _, f := range oldFiles {
		if filepath.Base(f) != filepath.Base(compactFileName) {
			_ = os.Remove(f)
		}
	}

	// 7. é‡å‘½ååˆå¹¶æ–‡ä»¶
	newName := filepath.Join(db.config.DataPath, "1.data")
	if err := os.Rename(compactFileName, newName); err != nil {
		return fmt.Errorf("é‡å‘½ååˆå¹¶æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// 8. æ›´æ–°å…ƒæ•°æ®
	db.activeFileID = 1
	db.keyDir = NewConcurrentMap(16)
	for key, kd := range newKeyDir {
		db.keyDir.Set(key, kd)
	}
	return db.openActiveFile()
}

// UIè¾…åŠ©å‡½æ•°

// printFancyBox æ‰“å°å¸¦è¾¹æ¡†çš„æ–‡æœ¬æ¡†
func printFancyBox(title string, content []string, color string, width int) {
	if width < 50 {
		width = 50
	}

	// æ‰“å°é¡¶éƒ¨è¾¹æ¡†
	fmt.Printf("%sâ”Œ", color)
	for i := 0; i < width-2; i++ {
		fmt.Print("â”€")
	}
	fmt.Printf("â”%s\n", ColorReset)

	// æ‰“å°æ ‡é¢˜è¡Œ
	titleRealLen := calculateRealLength(title)
	titlePadding := width - titleRealLen - 2
	leftPadding := titlePadding / 2
	rightPadding := titlePadding - leftPadding

	fmt.Printf("%sâ”‚%s", color, ColorReset)
	for i := 0; i < leftPadding; i++ {
		fmt.Print(" ")
	}
	fmt.Print(title)
	for i := 0; i < rightPadding; i++ {
		fmt.Print(" ")
	}
	fmt.Printf("%sâ”‚%s\n", color, ColorReset)

	// æ‰“å°åˆ†éš”çº¿
	fmt.Printf("%sâ”œ", color)
	for i := 0; i < width-2; i++ {
		fmt.Print("â”€")
	}
	fmt.Printf("â”¤%s\n", ColorReset)

	// æ‰“å°å†…å®¹è¡Œ
	for _, line := range content {
		// è®¡ç®—è¿™ä¸€è¡Œçš„å®é™…æ˜¾ç¤ºé•¿åº¦
		lineRealLen := calculateRealLength(line)

		// è®¡ç®—éœ€è¦å¡«å……çš„ç©ºæ ¼æ•°é‡
		// width-2 æ˜¯æ€»å¯ç”¨ç©ºé—´ï¼Œ-1 æ˜¯å·¦è¾¹ç©ºæ ¼ï¼ŒlineRealLen æ˜¯å†…å®¹é•¿åº¦
		paddingNeeded := width - 2 - 1 - lineRealLen

		// ç¡®ä¿paddingä¸ä¸ºè´Ÿæ•°
		if paddingNeeded < 0 {
			paddingNeeded = 0
		}

		// æ‰“å°ï¼šå·¦è¾¹æ¡† + ç©ºæ ¼ + å†…å®¹ + å¡«å……ç©ºæ ¼ + å³è¾¹æ¡†
		fmt.Printf("%sâ”‚%s %s", color, ColorReset, line)
		for i := 0; i < paddingNeeded; i++ {
			fmt.Print(" ")
		}
		fmt.Printf("%sâ”‚%s\n", color, ColorReset)
	}

	// æ‰“å°åº•éƒ¨è¾¹æ¡†
	fmt.Printf("%sâ””", color)
	for i := 0; i < width-2; i++ {
		fmt.Print("â”€")
	}
	fmt.Printf("â”˜%s\n", ColorReset)
}

// calculateRealLength è®¡ç®—å­—ç¬¦ä¸²çš„å®é™…æ˜¾ç¤ºå®½åº¦
func calculateRealLength(s string) int {
	length := 0
	inEscape := false
	i := 0

	for i < len(s) {
		if i+1 < len(s) && s[i] == '\x1b' && s[i+1] == '[' {
			// è·³è¿‡ANSIè½¬ä¹‰åºåˆ—
			inEscape = true
			i += 2
			continue
		}

		if inEscape {
			if s[i] == 'm' {
				inEscape = false
			}
			i++
			continue
		}

		// è·å–å½“å‰å­—ç¬¦çš„UTF-8ç¼–ç 
		r, size := utf8.DecodeRuneInString(s[i:])
		if r == utf8.RuneError {
			i++
			continue
		}

		// è®¡ç®—å­—ç¬¦çš„æ˜¾ç¤ºå®½åº¦
		width := getRuneWidth(r)
		length += width
		i += size
	}

	return length
}

// getRuneWidth è·å–å­—ç¬¦çš„æ˜¾ç¤ºå®½åº¦
func getRuneWidth(r rune) int {
	// ASCIIå­—ç¬¦
	if r < 0x80 {
		return 1
	}

	// å¸¸è§çš„emojiå’Œç¬¦å·å­—ç¬¦
	if isEmoji(r) {
		return 2 // å¤§å¤šæ•°emojiå 2ä¸ªå­—ç¬¦å®½åº¦
	}

	// ä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰å®½å­—ç¬¦
	if isWideChar(r) {
		return 2
	}

	// å…¶ä»–Unicodeå­—ç¬¦
	return 1
}

// isEmoji åˆ¤æ–­æ˜¯å¦ä¸ºemojiå­—ç¬¦
func isEmoji(r rune) bool {
	// å¸¸è§çš„emojièŒƒå›´
	return (r >= 0x1F600 && r <= 0x1F64F) || // è¡¨æƒ…ç¬¦å·
		(r >= 0x1F300 && r <= 0x1F5FF) || // æ‚é¡¹ç¬¦å·å’Œè±¡å½¢æ–‡å­—
		(r >= 0x1F680 && r <= 0x1F6FF) || // äº¤é€šå’Œåœ°å›¾ç¬¦å·
		(r >= 0x1F700 && r <= 0x1F77F) || // ç‚¼é‡‘æœ¯ç¬¦å·
		(r >= 0x1F780 && r <= 0x1F7FF) || // å‡ ä½•å›¾å½¢æ‰©å±•
		(r >= 0x1F800 && r <= 0x1F8FF) || // è¡¥å……ç®­å¤´-C
		(r >= 0x1F900 && r <= 0x1F9FF) || // è¡¥å……ç¬¦å·å’Œè±¡å½¢æ–‡å­—
		(r >= 0x1FA00 && r <= 0x1FA6F) || // æ£‹ç±»ç¬¦å·
		(r >= 0x1FA70 && r <= 0x1FAFF) || // æ‰©å±•-Aç¬¦å·å’Œè±¡å½¢æ–‡å­—
		(r >= 0x2600 && r <= 0x26FF) || // æ‚é¡¹ç¬¦å·
		(r >= 0x2700 && r <= 0x27BF) || // è£…é¥°ç¬¦å·
		(r >= 0x1F1E6 && r <= 0x1F1FF) // åŒºåŸŸæŒ‡ç¤ºç¬¦å·
}

// isWideChar åˆ¤æ–­æ˜¯å¦ä¸ºå…¨è§’å­—ç¬¦
func isWideChar(r rune) bool {
	// ä¸­æ–‡å­—ç¬¦èŒƒå›´
	return (r >= 0x4E00 && r <= 0x9FFF) || // CJKç»Ÿä¸€æ±‰å­—
		(r >= 0x3400 && r <= 0x4DBF) || // CJKæ‰©å±•A
		(r >= 0x20000 && r <= 0x2A6DF) || // CJKæ‰©å±•B
		(r >= 0x2A700 && r <= 0x2B73F) || // CJKæ‰©å±•C
		(r >= 0x2B740 && r <= 0x2B81F) || // CJKæ‰©å±•D
		(r >= 0x3000 && r <= 0x303F) || // CJKç¬¦å·å’Œæ ‡ç‚¹
		(r >= 0xFF00 && r <= 0xFFEF) // å…¨è§’ASCII
}

// é«˜çº§è¡¨æ ¼æ‰“å°å‡½æ•°
func printAdvancedTable(headers []string, rows [][]string, color string) {
	if len(headers) == 0 || len(rows) == 0 {
		return
	}

	// è®¡ç®—æ¯åˆ—çš„æœ€å¤§å®½åº¦
	colWidths := make([]int, len(headers))
	for i, header := range headers {
		colWidths[i] = len(header) + 2 // åŠ ä¸Šè¾¹è·
	}

	for _, row := range rows {
		for i, cell := range row {
			if i < len(colWidths) {
				cellLen := len(removeColorCodes(cell)) + 2
				if cellLen > colWidths[i] {
					colWidths[i] = cellLen
				}
			}
		}
	}

	// æ‰“å°é¡¶éƒ¨è¾¹æ¡†
	fmt.Printf("\n%s%s", color, BoxTopLeft)
	for i, width := range colWidths {
		fmt.Printf("%s", strings.Repeat(BoxHorizontal, width))
		if i < len(colWidths)-1 {
			fmt.Printf("%s", BoxTeeDown)
		}
	}
	fmt.Printf("%s%s\n", BoxTopRight, ColorReset)

	// æ‰“å°è¡¨å¤´
	fmt.Printf("%s%s", color, BoxVertical)
	for i, header := range headers {
		fmt.Printf(" %s%-*s", ColorBold+ColorWhite, colWidths[i]-2, header)
		fmt.Printf("%s%s", ColorReset+color, BoxVertical)
	}
	fmt.Printf("%s\n", ColorReset)

	// æ‰“å°åˆ†éš”çº¿
	fmt.Printf("%s%s", color, BoxTeeRight)
	for i, width := range colWidths {
		fmt.Printf("%s", strings.Repeat(BoxHorizontal, width))
		if i < len(colWidths)-1 {
			fmt.Printf("%s", BoxCross)
		}
	}
	fmt.Printf("%s%s\n", BoxTeeLeft, ColorReset)

	// æ‰“å°æ•°æ®è¡Œ
	for _, row := range rows {
		fmt.Printf("%s%s", color, BoxVertical)
		for i, cell := range row {
			if i < len(colWidths) {
				removeColorCodes(cell)
				fmt.Printf(" %-*s", colWidths[i]-2, cell)
				fmt.Printf("%s%s", color, BoxVertical)
			}
		}
		fmt.Printf("%s\n", ColorReset)
	}

	// æ‰“å°åº•éƒ¨è¾¹æ¡†
	fmt.Printf("%s%s", color, BoxBottomLeft)
	for i, width := range colWidths {
		fmt.Printf("%s", strings.Repeat(BoxHorizontal, width))
		if i < len(colWidths)-1 {
			fmt.Printf("%s", BoxTeeUp)
		}
	}
	fmt.Printf("%s%s\n", BoxBottomRight, ColorReset)
}

// ç§»é™¤é¢œè‰²ä»£ç ä»¥è®¡ç®—å®é™…é•¿åº¦
func removeColorCodes(s string) string {
	result := s
	colorCodes := []string{ColorReset, ColorRed, ColorGreen, ColorYellow,
		ColorBlue, ColorPurple, ColorCyan, ColorWhite, ColorBold, ColorDim}

	for _, code := range colorCodes {
		result = strings.ReplaceAll(result, code, "")
	}
	return result
}

// getCompressionName è·å–å‹ç¼©ç±»å‹åç§°
func getCompressionName(compression CompressionType) string {
	switch compression {
	case NoCompression:
		return "æ— å‹ç¼©"
	case SnappyCompression:
		return "Snappy"
	case ZSTDCompression:
		return "ZSTD"
	case GzipCompression:
		return "Gzip"
	default:
		return "æœªçŸ¥"
	}
}

// getBoolString è·å–å¸ƒå°”å€¼å­—ç¬¦ä¸²
func getBoolString(b bool) string {
	if b {
		return "âœ… å¯ç”¨"
	}
	return "âŒ ç¦ç”¨"
}

// formatDuration æ ¼å¼åŒ–æ—¶é—´é—´éš”
func formatDuration(d time.Duration) string {
	if d < time.Minute {
		return fmt.Sprintf("%.1fç§’", d.Seconds())
	} else if d < time.Hour {
		return fmt.Sprintf("%.1fåˆ†é’Ÿ", d.Minutes())
	} else if d < 24*time.Hour {
		return fmt.Sprintf("%.1få°æ—¶", d.Hours())
	} else {
		return fmt.Sprintf("%.1få¤©", d.Hours()/24)
	}
}

// PrintDatabaseOverview æ‰“å°æ•°æ®åº“æ¦‚è§ˆ
func (db *GojiDB) PrintDatabaseOverview() {
	keys := db.ListKeys()
	totalKeys := len(keys)

	// ç»Ÿè®¡è¿‡æœŸé”®
	expiredKeys := 0
	deletedKeys := 0
	now := uint32(time.Now().Unix())

	db.mu.RLock()
	db.keyDir.Range(func(key string, keyDir *KeyDir) bool {
		if keyDir.Deleted {
			deletedKeys++
		} else if keyDir.TTL > 0 && now > keyDir.TTL {
			expiredKeys++
		}
		return true
	})
	totalStoredKeys := db.keyDir.Size()
	db.mu.RUnlock()

	// è®¡ç®—æ•°æ®æ–‡ä»¶å¤§å°
	var totalSize int64
	files, err := filepath.Glob(filepath.Join(db.config.DataPath, "*.data"))
	if err == nil {
		for _, file := range files {
			if stat, err := os.Stat(file); err == nil {
				totalSize += stat.Size()
			}
		}
	}

	// è®¡ç®—è¿è¡Œæ—¶é—´
	uptime := time.Since(db.metrics.StartTime)

	content := []string{
		fmt.Sprintf("ğŸ—‚ï¸  æ•°æ®ç›®å½•:      %s%s%s", ColorCyan, db.config.DataPath, ColorReset),
		fmt.Sprintf("ğŸ“  æ´»è·ƒæ–‡ä»¶ID:    %s%d%s", ColorYellow, db.activeFileID, ColorReset),
		fmt.Sprintf("ğŸ”‘  æ´»è·ƒé”®æ•°é‡:    %s%d%s", ColorGreen, totalKeys, ColorReset),
		fmt.Sprintf("ğŸ“¦  æ€»å­˜å‚¨é”®æ•°:    %s%d%s", ColorBlue, totalStoredKeys, ColorReset),
		fmt.Sprintf("ğŸ—‘ï¸  å·²åˆ é™¤é”®æ•°:    %s%d%s", ColorRed, deletedKeys, ColorReset),
		fmt.Sprintf("â°  å·²è¿‡æœŸé”®æ•°:    %s%d%s", ColorYellow, expiredKeys, ColorReset),
		fmt.Sprintf("ğŸ’¾  æ•°æ®æ–‡ä»¶å¤§å°:  %s%s%s", ColorPurple, formatSize(totalSize), ColorReset),
		fmt.Sprintf("ğŸ—œï¸  å‹ç¼©ç±»å‹:      %s%s%s", ColorGreen, db.getCurrentCompressionType(), ColorReset),
		fmt.Sprintf("ğŸ“Š  ç›‘æ§çŠ¶æ€:      %s%s%s", ColorCyan, getBoolString(db.config.EnableMetrics), ColorReset),
		fmt.Sprintf("â±ï¸  è¿è¡Œæ—¶é—´:      %s%s%s", ColorBlue, formatDuration(uptime), ColorReset),
	}

	printFancyBox("ğŸ“Š æ•°æ®åº“çŠ¶æ€æ¦‚è§ˆ", content, ColorGreen, 70)
}

// PrintDataVisualization æ‰“å°æ•°æ®å¯è§†åŒ–
func (db *GojiDB) PrintDataVisualization() {
	keys := db.ListKeys()
	if len(keys) == 0 {
		fmt.Printf("\n%sğŸ“Š æ•°æ®å¯è§†åŒ–%s\n", ColorBold+ColorBlue, ColorReset)
		fmt.Printf("%sæ•°æ®åº“ä¸ºç©ºï¼Œæ²¡æœ‰æ•°æ®å¯ä»¥æ˜¾ç¤º%s\n", ColorYellow, ColorReset)
		return
	}

	fmt.Printf("\n%s%s æ•°æ®å¯è§†åŒ– %s%s\n", ColorBold+ColorBlue,
		strings.Repeat("â•", 30), strings.Repeat("â•", 30), ColorReset)

	// æŒ‰é”®ç±»å‹åˆ†ç»„ç»Ÿè®¡
	keyTypes := make(map[string]int)
	keyTypeSizes := make(map[string]int64)

	db.mu.RLock()
	for _, key := range keys {
		if keyDir, exists := db.keyDir.Get(key); exists && !keyDir.Deleted {
			// æ ¹æ®é”®çš„å‰ç¼€åˆ†ç±»
			parts := strings.Split(key, ":")
			keyType := "å…¶ä»–"
			if len(parts) > 1 {
				keyType = parts[0]
			}

			keyTypes[keyType]++
			keyTypeSizes[keyType] += int64(keyDir.ValueSize)
		}
	}
	db.mu.RUnlock()

	// æ˜¾ç¤ºé”®ç±»å‹åˆ†å¸ƒ
	fmt.Printf("\n%sğŸ”‘ é”®ç±»å‹åˆ†å¸ƒ:%s\n", ColorBold+ColorGreen, ColorReset)

	maxCount := 0
	for _, count := range keyTypes {
		if count > maxCount {
			maxCount = count
		}
	}

	// é˜²æ­¢é™¤ä»¥é›¶é”™è¯¯
	if maxCount == 0 {
		fmt.Printf("  %sæ²¡æœ‰æœ‰æ•ˆçš„é”®ç±»å‹æ•°æ®%s\n", ColorYellow, ColorReset)
		return
	}

	for keyType, count := range keyTypes {
		barLength := (count * 40) / maxCount
		if barLength == 0 && count > 0 {
			barLength = 1
		}

		bar := strings.Repeat("â–ˆ", barLength) + strings.Repeat("â–‘", 40-barLength)
		percentage := float64(count) / float64(len(keys)) * 100

		fmt.Printf("  %-12s %s%s%s %s%3d%s (%s%.1f%%%s)\n",
			keyType, ColorCyan, bar, ColorReset,
			ColorYellow, count, ColorReset,
			ColorGreen, percentage, ColorReset)
	}

	// æ˜¾ç¤ºæ•°æ®å¤§å°åˆ†å¸ƒ
	fmt.Printf("\n%sğŸ’¾ æ•°æ®å¤§å°åˆ†å¸ƒ:%s\n", ColorBold+ColorPurple, ColorReset)

	maxSize := int64(0)
	for _, size := range keyTypeSizes {
		if size > maxSize {
			maxSize = size
		}
	}

	// é˜²æ­¢é™¤ä»¥é›¶é”™è¯¯
	if maxSize == 0 {
		fmt.Printf("  %sæ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¤§å°ä¿¡æ¯%s\n", ColorYellow, ColorReset)
		return
	}

	for keyType, size := range keyTypeSizes {
		barLength := int((size * 40) / maxSize)
		if barLength == 0 && size > 0 {
			barLength = 1
		}

		bar := strings.Repeat("â–ˆ", barLength) + strings.Repeat("â–‘", 40-barLength)

		fmt.Printf("  %-12s %s%s%s %s%8s%s\n",
			keyType, ColorPurple, bar, ColorReset,
			ColorYellow, formatSize(size), ColorReset)
	}
}

// PrintFullDatabaseStatus æ‰“å°å®Œæ•´æ•°æ®åº“çŠ¶æ€
func (db *GojiDB) PrintFullDatabaseStatus() {
	// æ˜¾ç¤ºæ•°æ®åº“æ¦‚è§ˆ
	db.PrintDatabaseOverview()

	// æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–
	db.PrintDataVisualization()

	// æ–‡ä»¶ä¿¡æ¯
	files, err := filepath.Glob(filepath.Join(db.config.DataPath, "*.data"))
	if err == nil && len(files) > 0 {
		fmt.Printf("\n%sğŸ“ æ•°æ®æ–‡ä»¶è¯¦æƒ…:%s\n", ColorBold+ColorBlue, ColorReset)

		headers := []string{"æ–‡ä»¶ID", "æ–‡ä»¶å¤§å°", "ä¿®æ”¹æ—¶é—´", "çŠ¶æ€"}
		var rows [][]string

		sort.Strings(files)
		for _, file := range files {
			if stat, err := os.Stat(file); err == nil {
				fileID, _ := db.parseFileID(file)
				status := "åªè¯»"
				statusColor := ColorDim
				if fileID == db.activeFileID {
					status = "æ´»è·ƒ"
					statusColor = ColorGreen
				}

				rows = append(rows, []string{
					fmt.Sprintf("%s%d%s", ColorYellow, fileID, ColorReset),
					formatSize(stat.Size()),
					stat.ModTime().Format("01-02 15:04"),
					fmt.Sprintf("%s%s%s", statusColor, status, ColorReset),
				})
			}
		}

		printAdvancedTable(headers, rows, ColorBlue)
	}

	// æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
	if db.config.EnableMetrics {
		db.PrintMetrics()
	}
}

// PrintMetrics æ‰“å°æ€§èƒ½æŒ‡æ ‡
func (db *GojiDB) PrintMetrics() {
	metrics := db.GetMetrics()
	uptime := time.Since(metrics.StartTime)

	content := []string{
		fmt.Sprintf("ğŸ“– æ€»è¯»å–æ¬¡æ•°:     %s%s%s", ColorGreen, formatNumber(metrics.TotalReads), ColorReset),
		fmt.Sprintf("ğŸ“ æ€»å†™å…¥æ¬¡æ•°:     %s%s%s", ColorBlue, formatNumber(metrics.TotalWrites), ColorReset),
		fmt.Sprintf("ğŸ—‘ï¸ æ€»åˆ é™¤æ¬¡æ•°:     %s%s%s", ColorRed, formatNumber(metrics.TotalDeletes), ColorReset),
		fmt.Sprintf("ğŸ¯ ç¼“å­˜å‘½ä¸­:       %s%s%s", ColorGreen, formatNumber(metrics.CacheHits), ColorReset),
		fmt.Sprintf("âŒ ç¼“å­˜æœªå‘½ä¸­:     %s%s%s", ColorYellow, formatNumber(metrics.CacheMisses), ColorReset),
		fmt.Sprintf("ğŸ”„ åˆå¹¶æ¬¡æ•°:       %s%s%s", ColorPurple, formatNumber(metrics.CompactionCount), ColorReset),
		fmt.Sprintf("â° è¿‡æœŸé”®æ¸…ç†:     %s%s%s", ColorCyan, formatNumber(metrics.ExpiredKeyCount), ColorReset),
		fmt.Sprintf("ğŸ—œï¸ å‹ç¼©æ¯”:         %s%.4f%s", ColorBlue, float64(metrics.CompressionRatio)/100.0, ColorReset),
		fmt.Sprintf("â±ï¸ è¿è¡Œæ—¶é—´:       %s%s%s", ColorPurple, formatDuration(uptime), ColorReset),
	}

	// è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
	totalAccess := metrics.CacheHits + metrics.CacheMisses
	if totalAccess > 0 {
		hitRate := float64(metrics.CacheHits) / float64(totalAccess) * 100
		content = append(content, fmt.Sprintf("ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡:     %s%.2f%%%s", ColorGreen, hitRate, ColorReset))
	}

	// è®¡ç®—QPS
	if uptime.Seconds() > 0 {
		totalOps := metrics.TotalReads + metrics.TotalWrites + metrics.TotalDeletes
		qps := float64(totalOps) / uptime.Seconds()
		content = append(content, fmt.Sprintf("âš¡ å¹³å‡QPS:        %s%.2f%s", ColorYellow, qps, ColorReset))
	}

	printFancyBox("ğŸ“Š æ€§èƒ½æŒ‡æ ‡", content, ColorPurple, 70)
}

// getCurrentCompressionType è·å–å½“å‰å®é™…ä½¿ç”¨çš„å‹ç¼©ç±»å‹
func (db *GojiDB) getCurrentCompressionType() string {
	if db.smartCompressor != nil {
		// è·å–æ™ºèƒ½å‹ç¼©å™¨çš„ç»Ÿè®¡ä¿¡æ¯
		stats := db.smartCompressor.GetStats()
		return db.getCompressionNameFromString(stats.Algorithm)
	}
	// å¦‚æœæ²¡æœ‰æ™ºèƒ½å‹ç¼©å™¨ï¼Œä½¿ç”¨é…ç½®ä¸­çš„ç±»å‹
	return getCompressionName(db.config.CompressionType)
}

// getCompressionNameFromString ä»å­—ç¬¦ä¸²è·å–å‹ç¼©ç±»å‹åç§°
func (db *GojiDB) getCompressionNameFromString(algorithm string) string {
	switch algorithm {
	case "auto":
		return "æ™ºèƒ½å‹ç¼©"
	case "snappy":
		return "Snappy"
	case "zstd":
		return "ZSTD"
	case "gzip":
		return "Gzip"
	case "":
		return getCompressionName(db.config.CompressionType)
	default:
		return algorithm
	}
}

// formatNumber æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤º
func formatNumber(n int64) string {
	if n < 1000 {
		return fmt.Sprintf("%d", n)
	} else if n < 1000000 {
		return fmt.Sprintf("%.1fK", float64(n)/1000)
	} else if n < 1000000000 {
		return fmt.Sprintf("%.1fM", float64(n)/1000000)
	} else {
		return fmt.Sprintf("%.1fB", float64(n)/1000000000)
	}
}

func (db *GojiDB) GetMetrics() *Metrics {
	if !db.config.EnableMetrics {
		return nil
	}

	keyCount := int64(db.keyDir.Size())
	
	// è®¡ç®—æ•°æ®æ€»å¤§å°
	var dataSize int64
	files, _ := filepath.Glob(filepath.Join(db.config.DataPath, "*.data"))
	for _, file := range files {
		if stat, err := os.Stat(file); err == nil {
			dataSize += stat.Size()
		}
	}

	return &Metrics{
		TotalWrites:      atomic.LoadInt64(&db.metrics.TotalWrites),
		TotalReads:       atomic.LoadInt64(&db.metrics.TotalReads),
		TotalDeletes:     atomic.LoadInt64(&db.metrics.TotalDeletes),
		KeyCount:         keyCount,
		DataSize:         dataSize,
		CompressionRatio: atomic.LoadInt64(&db.metrics.CompressionRatio),
		CacheHits:        atomic.LoadInt64(&db.metrics.CacheHits),
		CacheMisses:      atomic.LoadInt64(&db.metrics.CacheMisses),
		ExpiredKeyCount:  atomic.LoadInt64(&db.metrics.ExpiredKeyCount),
		CompactionCount:  atomic.LoadInt64(&db.metrics.CompactionCount),
		StartTime:        db.metrics.StartTime,
		SystemInfo:       db.metrics.SystemInfo,
	}
}
