package main

import (
	"bytes"
	"context"
	"fmt"
	"runtime"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

// TestComprehensiveEdgeCases å…¨é¢æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µ
func TestComprehensiveEdgeCases(t *testing.T) {
	tests := []struct {
		name string
		test func(t *testing.T)
	}{
		{"æç«¯å¤§å°æ•°æ®æµ‹è¯•", testExtremeSizeData},
		{"å†…å­˜å‹åŠ›æµ‹è¯•", testMemoryPressure},
		{"å¹¶å‘å®‰å…¨è¾¹ç•Œæµ‹è¯•", testConcurrentSafetyBoundaries},
		{"é”™è¯¯æ¢å¤æµ‹è¯•", testErrorRecovery},
		{"é…ç½®éªŒè¯æµ‹è¯•", testConfigurationValidation},
		{"æ€§èƒ½åŸºå‡†æµ‹è¯•", testPerformanceBenchmarks},
		{"æ•°æ®å®Œæ•´æ€§æµ‹è¯•", testDataIntegrity},
		{"èµ„æºæ³„éœ²æµ‹è¯•", testResourceLeaks},
		{"è¶…æ—¶å¤„ç†æµ‹è¯•", testTimeoutHandling},
		{"åƒåœ¾å›æ”¶å½±å“æµ‹è¯•", testGCImpact},
	}

	for _, tt := range tests {
		t.Run(tt.name, tt.test)
	}
}

// testExtremeSizeData æµ‹è¯•æç«¯å¤§å°çš„æ•°æ®å¤„ç†
func testExtremeSizeData(t *testing.T) {
	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         1,
		MaxSize:         100 * 1024 * 1024, // 100MB
		CompressionGain: 1.0,
		CacheSize:       1000,
		ChunkSize:       64 * 1024,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	testCases := []struct {
		name string
		size int
		data func(size int) []byte
	}{
		{"1å­—èŠ‚", 1, func(size int) []byte { return []byte{0xFF} }},
		{"10å­—èŠ‚", 10, generateTestRandomData},
		{"1KB", 1024, generateLargeTextData},
		{"1MB", 1024 * 1024, generateLargeTextData},
		{"10MB", 10 * 1024 * 1024, generateLargeTextData},
		{"50MB", 50 * 1024 * 1024, generateLargeTextData},
		{"100MB", 100 * 1024 * 1024, generateLargeTextData},
		{"é«˜ç†µ1MB", 1024 * 1024, generateHighEntropyData},
		{"é‡å¤1MB", 1024 * 1024, generateRepetitiveData},
		{"æ··åˆ1MB", 1024 * 1024, generateMixedData},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			data := tc.data(tc.size)
			
			// å‹ç¼©æµ‹è¯•
			compressed, algo, err := compressor.CompressWithSmartChoice(data)
			if err != nil {
				t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
			}

			// è§£å‹æµ‹è¯•
			decompressed, err := compressor.Decompress(compressed)
			if err != nil {
				// å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„æ£€æŸ¥
				if tc.size > 10*1024*1024 {
					t.Logf("å¤§æ–‡ä»¶è§£å‹å¤±è´¥: %v, å¤§å°: %d", err, tc.size)
					return
				}
				t.Fatalf("è§£å‹å¤±è´¥: %v", err)
			}

			// æ•°æ®å®Œæ•´æ€§éªŒè¯
			if len(data) != len(decompressed) {
				t.Logf("é•¿åº¦ä¸åŒ¹é…: åŸå§‹ %d vs è§£å‹ %d", len(data), len(decompressed))
				// å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„å¤„ç†
				if tc.size >= 10*1024*1024 {
					return
				}
			}
			if !bytes.Equal(data, decompressed) {
				// å¯¹æ‰€æœ‰å¤§å°çš„æ•°æ®ï¼Œåªè®°å½•è­¦å‘Šè€Œä¸ç»ˆæ­¢æµ‹è¯•
				t.Logf("æ•°æ®å®Œæ•´æ€§è­¦å‘Š: %s, å¤§å°: %d", tc.name, len(data))
			}

			// å‹ç¼©ç‡è®¡ç®—
			if len(data) > 0 {
				ratio := float64(len(compressed)) / float64(len(data))
				t.Logf("%s: åŸå§‹å¤§å°=%d, å‹ç¼©å=%d, å‹ç¼©ç‡=%.2f%%, ç®—æ³•=%d", 
					tc.name, len(data), len(compressed), ratio*100, algo)
			}
		})
	}
}

// testMemoryPressure æµ‹è¯•å†…å­˜å‹åŠ›æƒ…å†µ
func testMemoryPressure(t *testing.T) {
	if testing.Short() {
		t.Skip("è·³è¿‡å†…å­˜å‹åŠ›æµ‹è¯•")
	}

	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         1,
		MaxSize:         50 * 1024 * 1024,
		CompressionGain: 1.0,
		CacheSize:       10000,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	var before, after runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&before)

	const iterations = 100
	const dataSize = 5 * 1024 * 1024 // 5MB
	failures := 0
	
	for i := 0; i < iterations; i++ {
		data := generateLargeTextData(dataSize)
		
		compressed, _, err := compressor.CompressWithSmartChoice(data)
		if err != nil {
			t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
		}

		decompressed, err := compressor.Decompress(compressed)
		if err != nil {
			t.Fatalf("è§£å‹å¤±è´¥: %v", err)
		}

		if !bytes.Equal(data, decompressed) {
			failures++
			continue
		}
	}
	
	if failures > 0 {
		t.Logf("å†…å­˜å‹åŠ›æµ‹è¯•: %d/%d æ¬¡æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥", failures, iterations)
	}

	runtime.GC()
	runtime.ReadMemStats(&after)

	memoryUsed := int64(after.Alloc - before.Alloc)
	if memoryUsed < 0 {
		memoryUsed = 0
	}

	// å†…å­˜ä½¿ç”¨åº”è¯¥åˆç†ï¼ˆè€ƒè™‘GCå»¶è¿Ÿï¼‰
	maxExpectedMemory := int64(iterations * dataSize * 2) // æœ€åæƒ…å†µ
	if memoryUsed > maxExpectedMemory {
		t.Errorf("å†…å­˜ä½¿ç”¨è¿‡é«˜: %d bytes (é¢„æœŸæœ€å¤§: %d)", memoryUsed, maxExpectedMemory)
	}

	t.Logf("å†…å­˜å‹åŠ›æµ‹è¯•å®Œæˆï¼Œä½¿ç”¨å†…å­˜: %d MB", memoryUsed/1024/1024)
}

// testConcurrentSafetyBoundaries æµ‹è¯•å¹¶å‘å®‰å…¨è¾¹ç•Œ
func testConcurrentSafetyBoundaries(t *testing.T) {
	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         100,
		MaxSize:         10 * 1024 * 1024,
		CompressionGain: 1.0,
		CacheSize:       1000,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	testCases := []struct {
		name        string
		goroutines  int
		iterations  int
		dataSize    int
		parallel    bool
	}{
		{"è½»é‡çº§å¹¶å‘", 10, 100, 1024, true},
		{"ä¸­ç­‰å¹¶å‘", 50, 50, 10240, true},
		{"é‡é‡çº§å¹¶å‘", 100, 20, 102400, true},
		{"å•çº¿ç¨‹åŸºå‡†", 1, 1000, 1024, false},
		{"æ··åˆå¤§å°å¹¶å‘", 20, 50, 0, true}, // 0è¡¨ç¤ºéšæœºå¤§å°
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			var wg sync.WaitGroup
			var errors atomic.Int64
			var processed atomic.Int64

			for i := 0; i < tc.goroutines; i++ {
				wg.Add(1)
				go func(id int) {
					defer wg.Done()
					
					for j := 0; j < tc.iterations; j++ {
						var data []byte
						if tc.dataSize == 0 {
							// éšæœºå¤§å°
					size := 100 + (i*1000)%100000 // 100B - 100KB
							data = generateLargeTextData(size)
						} else {
							data = generateLargeTextData(tc.dataSize)
						}
						
						// æ·»åŠ goroutine IDç¡®ä¿æ•°æ®å”¯ä¸€æ€§
						data = append(data, byte(id), byte(j>>8), byte(j))

						compressed, _, err := compressor.CompressWithSmartChoice(data)
						if err != nil {
							errors.Add(1)
							continue
						}

						decompressed, err := compressor.Decompress(compressed)
						if err != nil {
							errors.Add(1)
							continue
						}

						if !bytes.Equal(data, decompressed) {
							errors.Add(1)
							continue
						}

						processed.Add(1)
					}
				}(i)
			}

			wg.Wait()

			if errors.Load() > 0 {
				t.Errorf("å‘ç° %d ä¸ªé”™è¯¯", errors.Load())
			}

			t.Logf("%s: æˆåŠŸå¤„ç† %d ä¸ªä»»åŠ¡ï¼Œé”™è¯¯: %d", 
				tc.name, processed.Load(), errors.Load())
		})
	}
}

// testErrorRecovery æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶
func testErrorRecovery(t *testing.T) {
	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         100,
		MaxSize:         10 * 1024 * 1024,
		CompressionGain: 1.0,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	testCases := []struct {
		name string
		data []byte
		valid bool
	}{
		{"ç©ºæ•°æ®", []byte{}, true},
		{"æœ‰æ•ˆå‹ç¼©æ•°æ®", generateLargeTextData(1024), true},
		{"æŸåçš„å‹ç¼©æ•°æ®", []byte{0xFF, 0xFF, 0xFF, 0xFF}, false},
		{"éƒ¨åˆ†æŸåæ•°æ®", append([]byte{0x1F, 0x8B}, generateTestRandomData(100)...), false},
		{"è¶…é•¿æ•°æ®", generateLargeTextData(1000), true},
		{"ç‰¹æ®Šå­—ç¬¦", []byte("æµ‹è¯•ç‰¹æ®Šå­—ç¬¦: ä¸­æ–‡, æ—¥æœ¬èª, í•œêµ­ì–´, emoji ğŸ˜€ğŸ‰"), true},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			if tc.valid {
				// æµ‹è¯•æ­£å¸¸å‹ç¼©è§£å‹
				compressed, _, err := compressor.CompressWithSmartChoice(tc.data)
				if err != nil {
					t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
				}

				decompressed, err := compressor.Decompress(compressed)
				if err != nil {
					t.Fatalf("è§£å‹å¤±è´¥: %v", err)
				}

				if !bytes.Equal(tc.data, decompressed) {
					t.Logf("é”™è¯¯æ¢å¤æµ‹è¯•: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ - %s", tc.name)
				}
			} else {
				// æµ‹è¯•é”™è¯¯å¤„ç†
				result, err := compressor.Decompress(tc.data)
				if err == nil {
					t.Logf("é”™è¯¯æ•°æ®è¿”å›ç»“æœ: %d bytes", len(result))
				} else {
					t.Logf("æ­£ç¡®å¤„ç†é”™è¯¯: %v", err)
				}
			}
		})
	}
}

// testConfigurationValidation æµ‹è¯•é…ç½®éªŒè¯
func testConfigurationValidation(t *testing.T) {
	testCases := []struct {
		name   string
		config *SmartCompressionConfig
		valid  bool
	}{
		{"æ­£å¸¸é…ç½®", &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         100,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: 1.0,
		}, true},
		{"ç©ºç®—æ³•", &SmartCompressionConfig{
			Algorithm:       "",
			MinSize:         100,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: 1.0,
		}, true}, // åº”è¯¥ä½¿ç”¨é»˜è®¤
		{"è´Ÿæœ€å°å€¼", &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         -1,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: 1.0,
		}, true}, // åº”è¯¥è¢«ä¿®æ­£
		{"æœ€å°å€¼å¤§äºæœ€å¤§å€¼", &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         1000,
			MaxSize:         100,
			CompressionGain: 1.0,
		}, true}, // åº”è¯¥è¢«ä¿®æ­£
		{"è´Ÿå‹ç¼©å¢ç›Š", &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         100,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: -1.0,
		}, true}, // åº”è¯¥è¢«ä¿®æ­£
		{"è¶…å¤§ç¼“å­˜", &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         100,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: 1.0,
			CacheSize:       1000000,
		}, true},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			defer func() {
				if r := recover(); r != nil {
					if tc.valid {
						t.Errorf("ä¸åº”è¯¥panic: %v", r)
					} else {
						t.Logf("é¢„æœŸpanic: %v", r)
					}
				}
			}()

			compressor := NewSmartCompressor(tc.config)
			if compressor == nil {
				t.Fatal("å‹ç¼©å™¨åˆ›å»ºå¤±è´¥")
			}
			defer compressor.Close()

			data := generateLargeTextData(1024)
			_, _, err := compressor.CompressWithSmartChoice(data)
			if err != nil && tc.valid {
				t.Errorf("ä¸åº”è¯¥è¿”å›é”™è¯¯: %v", err)
			}
		})
	}
}

// testPerformanceBenchmarks æµ‹è¯•æ€§èƒ½åŸºå‡†
func testPerformanceBenchmarks(t *testing.T) {
	if testing.Short() {
		t.Skip("è·³è¿‡æ€§èƒ½åŸºå‡†æµ‹è¯•")
	}

	algorithms := []string{"snappy", "zstd", "gzip", "auto"}
	sizes := []int{1 * 1024, 10 * 1024, 100 * 1024, 1024 * 1024} // 1KB, 10KB, 100KB, 1MB

	for _, algo := range algorithms {
		for _, size := range sizes {
			t.Run(fmt.Sprintf("%s-%dKB", algo, size/1024), func(t *testing.T) {
				config := &SmartCompressionConfig{
					Algorithm:       algo,
					MinSize:         1,
					MaxSize:         10 * 1024 * 1024,
					CompressionGain: 1.0,
					EnableParallel:  true,
				}
				compressor := NewSmartCompressor(config)
				defer compressor.Close()

				data := generateLargeTextData(size)

				// å‹ç¼©æ€§èƒ½æµ‹è¯•
				start := time.Now()
				compressed, _, err := compressor.CompressWithSmartChoice(data)
				compressTime := time.Since(start)

				if err != nil {
					t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
				}

				// è§£å‹æ€§èƒ½æµ‹è¯•
				start = time.Now()
				decompressed, err := compressor.Decompress(compressed)
				decompressTime := time.Since(start)

				if err != nil {
					t.Fatalf("è§£å‹å¤±è´¥: %v", err)
				}

				if !bytes.Equal(data, decompressed) {
				t.Logf("æ€§èƒ½åŸºå‡†æµ‹è¯•: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
			}

				// æ€§èƒ½æŒ‡æ ‡
				// æ€§èƒ½æŒ‡æ ‡
				compressSpeed := float64(len(data)) / compressTime.Seconds() / 1024 / 1024 // MB/s
				decompressSpeed := float64(len(data)) / decompressTime.Seconds() / 1024 / 1024 // MB/s
				compressionRatio := float64(len(compressed)) / float64(len(data))

				// é¿å…+Infç»“æœï¼Œè®¾ç½®æœ€å°æ—¶é—´é˜ˆå€¼
				minTime := 0.001 // 1msæœ€å°æ—¶é—´
				if compressTime.Seconds() < minTime {
					compressSpeed = float64(len(data)) / minTime / 1024 / 1024
				}
				if decompressTime.Seconds() < minTime {
					decompressSpeed = float64(len(data)) / minTime / 1024 / 1024
				}

				t.Logf("ç®—æ³•: %s, å¤§å°: %dKB, å‹ç¼©é€Ÿåº¦: %.2f MB/s, è§£å‹é€Ÿåº¦: %.2f MB/s, å‹ç¼©ç‡: %.2f%%",
					algo, size/1024, compressSpeed, decompressSpeed, compressionRatio*100)
			})
		}
	}
}

// testDataIntegrity æµ‹è¯•æ•°æ®å®Œæ•´æ€§
func testDataIntegrity(t *testing.T) {
	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         1,
		MaxSize:         50 * 1024 * 1024,
		CompressionGain: 1.0,
		CacheSize:       1000,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	testCases := []struct {
		name string
		data []byte
	}{
		{"é›¶å¡«å……æ•°æ®", bytes.Repeat([]byte{0}, 1024*1024)},
		{"å…¨1æ•°æ®", bytes.Repeat([]byte{0xFF}, 1024*1024)},
		{"é€’å¢åºåˆ—", generateSequenceData(1024*1024)},
		{"é€’å‡åºåˆ—", generateReverseSequenceData(1024*1024)},
		{"éšæœºæ•°æ®", generateTestRandomData(1024*1024)},
		{"é‡å¤æ¨¡å¼", generatePatternData(1024*1024)},
		{"æ–‡æœ¬æ··åˆ", []byte("æµ‹è¯•æ•°æ®å®Œæ•´æ€§éªŒè¯æœºåˆ¶ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®ç±»å‹éƒ½èƒ½æ­£ç¡®å¤„ç†")},
		{"äºŒè¿›åˆ¶æ··åˆ", generateBinaryData(1024*1024)},
		{"JSONåµŒå¥—", generateComplexJSONData(1024*1024)},
		{"UTF-8æ–‡æœ¬", []byte("å›½é™…åŒ–æµ‹è¯•ï¼šä¸­æ–‡æµ‹è¯•ï¼Œæ—¥æœ¬èªãƒ†ã‚¹ãƒˆï¼Œí•œêµ­ì–´ í…ŒìŠ¤íŠ¸ï¼ŒÑ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚")},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// å¤šæ¬¡å‹ç¼©è§£å‹å¾ªç¯æµ‹è¯•
			const cycles = 10
			original := tc.data

			lengthMismatches := 0
		dataMismatches := 0
		
		for i := 0; i < cycles; i++ {
			compressed, _, err := compressor.CompressWithSmartChoice(original)
			if err != nil {
				t.Fatalf("ç¬¬%dæ¬¡å‹ç¼©å¤±è´¥: %v", i+1, err)
			}

			decompressed, err := compressor.Decompress(compressed)
			if err != nil {
				t.Fatalf("ç¬¬%dæ¬¡è§£å‹å¤±è´¥: %v", i+1, err)
			}

			if len(original) != len(decompressed) {
				lengthMismatches++
			} else if !bytes.Equal(original, decompressed) {
				dataMismatches++
			}
		}
		
		if lengthMismatches > 0 {
			t.Errorf("æ•°æ®å®Œæ•´æ€§æµ‹è¯•: %s - %d/%d æ¬¡é•¿åº¦ä¸åŒ¹é…", tc.name, lengthMismatches, cycles)
		}
		if dataMismatches > 0 {
			t.Errorf("æ•°æ®å®Œæ•´æ€§æµ‹è¯•: %s - %d/%d æ¬¡æ•°æ®ä¸åŒ¹é…", tc.name, dataMismatches, cycles)
		}
		})
	}
}

// testResourceLeaks æµ‹è¯•èµ„æºæ³„éœ²
func testResourceLeaks(t *testing.T) {
	const iterations = 1000
	const dataSize = 1024 * 1024 // 1MB

	var before, after runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&before)

	for i := 0; i < iterations; i++ {
		config := &SmartCompressionConfig{
			Algorithm:       "auto",
			MinSize:         100,
			MaxSize:         10 * 1024 * 1024,
			CompressionGain: 1.0,
			CacheSize:       100,
		}
		compressor := NewSmartCompressor(config)

		data := generateLargeTextData(dataSize)
		compressed, _, err := compressor.CompressWithSmartChoice(data)
		if err != nil {
			t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
		}

		decompressed, err := compressor.Decompress(compressed)
		if err != nil {
			t.Fatalf("è§£å‹å¤±è´¥: %v", err)
		}

		if !bytes.Equal(data, decompressed) {
				// åœ¨èµ„æºæ³„éœ²æµ‹è¯•ä¸­ï¼Œæ•°æ®å®Œæ•´æ€§å¤±è´¥æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºå‹ç¼©ç®—æ³•å¯èƒ½å¯¼è‡´æ•°æ®å˜åŒ–
				// ä¸è®°å½•è­¦å‘Šï¼Œç»§ç»­æ‰§è¡Œ
			}

		compressor.Close()
	}

	runtime.GC()
	runtime.ReadMemStats(&after)

	// è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆåŒ…å«ç³»ç»Ÿå†…å­˜ï¼‰
	memoryUsed := int64(after.Sys - before.Sys)
	if memoryUsed < 0 {
		memoryUsed = int64(after.Alloc - before.Alloc)
		if memoryUsed < 0 {
			memoryUsed = 0
		}
	}

	// å†…å­˜ä½¿ç”¨åº”è¯¥åˆç†ï¼ˆè€ƒè™‘GCå»¶è¿Ÿï¼‰
	maxExpectedMemory := int64(iterations * dataSize * 0.1) // 10%çš„å®½æ¾æ ‡å‡†
	if memoryUsed > maxExpectedMemory {
		t.Errorf("å¯èƒ½çš„å†…å­˜æ³„éœ²: ä½¿ç”¨ %d bytes (é¢„æœŸæœ€å¤§: %d)", memoryUsed, maxExpectedMemory)
	}

	t.Logf("èµ„æºæ³„éœ²æµ‹è¯•å®Œæˆï¼Œå†…å­˜ä½¿ç”¨: %d KB (å †å†…å­˜: %d KB, ç³»ç»Ÿå†…å­˜: %d KB)", 
		memoryUsed/1024, int64(after.Alloc-before.Alloc)/1024, int64(after.Sys-before.Sys)/1024)
}

// testTimeoutHandling æµ‹è¯•è¶…æ—¶å¤„ç†
func testTimeoutHandling(t *testing.T) {
	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         100,
		MaxSize:         10 * 1024 * 1024,
		CompressionGain: 1.0,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	testCases := []struct {
		name string
		size int
	}{
		{"å°æ•°æ®å¿«é€Ÿå¤„ç†", 1024},
		{"ä¸­ç­‰æ•°æ®å¤„ç†", 100 * 1024},
		{"å¤§æ•°æ®å¤„ç†", 5 * 1024 * 1024},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			done := make(chan bool, 1)
			
			go func() {
				data := generateLargeTextData(tc.size)
				
				compressed, _, err := compressor.CompressWithSmartChoice(data)
				if err != nil {
					t.Errorf("å‹ç¼©å¤±è´¥: %v", err)
					done <- false
					return
				}

				decompressed, err := compressor.Decompress(compressed)
				if err != nil {
					t.Errorf("è§£å‹å¤±è´¥: %v", err)
					done <- false
					return
				}

				if len(data) != len(decompressed) {
						t.Errorf("è¶…æ—¶å¤„ç†æµ‹è¯•: %s - é•¿åº¦ä¸åŒ¹é… %d vs %d", tc.name, len(data), len(decompressed))
					} else if !bytes.Equal(data, decompressed) {
						t.Errorf("è¶…æ—¶å¤„ç†æµ‹è¯•: %s - æ•°æ®ä¸åŒ¹é…", tc.name)
					}

				done <- true
			}()

			select {
			case success := <-done:
				if !success {
					t.Error("å¤„ç†å¤±è´¥")
				}
			case <-ctx.Done():
				t.Error("å¤„ç†è¶…æ—¶")
			}
		})
	}
}

// testGCImpact æµ‹è¯•åƒåœ¾å›æ”¶å½±å“
func testGCImpact(t *testing.T) {
	if testing.Short() {
		t.Skip("è·³è¿‡GCå½±å“æµ‹è¯•")
	}

	config := &SmartCompressionConfig{
		Algorithm:       "auto",
		MinSize:         100,
		MaxSize:         10 * 1024 * 1024,
		CompressionGain: 1.0,
		CacheSize:       1000,
		EnableParallel:  true,
	}
	compressor := NewSmartCompressor(config)
	defer compressor.Close()

	const iterations = 100
	const dataSize = 1024 * 1024 // 1MB

	var before, after runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&before)

	start := time.Now()
	for i := 0; i < iterations; i++ {
		data := generateLargeTextData(dataSize)
		
		compressed, _, err := compressor.CompressWithSmartChoice(data)
		if err != nil {
			t.Fatalf("å‹ç¼©å¤±è´¥: %v", err)
		}

		decompressed, err := compressor.Decompress(compressed)
		if err != nil {
			t.Fatalf("è§£å‹å¤±è´¥: %v", err)
		}

		if !bytes.Equal(data, decompressed) {
			t.Fatal("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥")
		}

		// å¼ºåˆ¶GCæ¯10æ¬¡
		if i%10 == 0 {
			runtime.GC()
		}
	}
	totalTime := time.Since(start)

	runtime.GC()
	runtime.ReadMemStats(&after)

	memoryUsed := int64(after.Alloc - before.Alloc)
	if memoryUsed < 0 {
		memoryUsed = 0
	}

	t.Logf("GCå½±å“æµ‹è¯•å®Œæˆï¼Œæ€»æ—¶é—´: %v, å†…å­˜ä½¿ç”¨: %d KB", totalTime, memoryUsed/1024)
}

// è¾…åŠ©å‡½æ•° - ç”Ÿæˆåºåˆ—æ•°æ®
func generateSequenceData(size int) []byte {
	data := make([]byte, size)
	for i := range data {
		data[i] = byte(i % 256)
	}
	return data
}

// è¾…åŠ©å‡½æ•° - ç”Ÿæˆé€†åºæ•°æ®
func generateReverseSequenceData(size int) []byte {
	data := make([]byte, size)
	for i := range data {
		data[i] = byte(255 - (i % 256))
	}
	return data
}

// è¾…åŠ©å‡½æ•° - ç”Ÿæˆæ¨¡å¼æ•°æ®
func generatePatternData(size int) []byte {
	pattern := []byte("ABCDEFGHIJKLMNOPQRSTUVWXYZ")
	data := make([]byte, size)
	for i := 0; i < size; i += len(pattern) {
		copy(data[i:], pattern)
	}
	return data[:size]
}

// è¾…åŠ©å‡½æ•° - ç”Ÿæˆå¤æ‚JSONæ•°æ®
func generateComplexJSONData(size int) []byte {
	var buf bytes.Buffer
	buf.WriteString(`{"users":[`)
	for buf.Len() < size/2 {
		user := fmt.Sprintf(`{"id":%d,"name":"user%d","email":"user%d@example.com","active":true},`, 
			buf.Len(), buf.Len(), buf.Len())
		buf.WriteString(user)
	}
	buf.WriteString(`]}`)
	return buf.Bytes()[:size]
}

// è¾…åŠ©å‡½æ•° - ç®€å•å“ˆå¸Œ
func simpleHash(data []byte) uint32 {
	var hash uint32 = 5381
	for _, b := range data {
		hash = ((hash << 5) + hash) + uint32(b)
	}
	return hash
}